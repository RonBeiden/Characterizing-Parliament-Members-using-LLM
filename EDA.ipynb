{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.2)\n",
      "Collecting pyodbc\n",
      "  Downloading pyodbc-5.2.0-cp310-cp310-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pyodbc-5.2.0-cp310-cp310-win_amd64.whl (68 kB)\n",
      "   ---------------------------------------- 0.0/68.9 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 30.7/68.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 68.9/68.9 kB 751.7 kB/s eta 0:00:00\n",
      "Installing collected packages: pyodbc\n",
      "Successfully installed pyodbc-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -elenium (c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -elenium (c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder containing the CSV files\n",
    "folder_path = \"db_csv\"\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file name contains the pattern to remove\n",
    "    if file_name.endswith(\"_202103042023.csv\"):\n",
    "        # Construct the new file name\n",
    "        new_name = file_name.replace(\"_202103042023\", \"\")\n",
    "        \n",
    "        # Build full paths for renaming\n",
    "        old_file_path = os.path.join(folder_path, file_name)\n",
    "        new_file_path = os.path.join(folder_path, new_name)\n",
    "        \n",
    "        # Rename the file\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "        print(f\"Renamed: {file_name} -> {new_name}\")\n",
    "\n",
    "print(\"Renaming complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "def csv_to_ssms_table(csv_file_path, server, database, encoding='windows-1255'):\n",
    "    \"\"\"\n",
    "    Reads a CSV file into a pandas DataFrame and inserts its contents into a SQL Server table.\n",
    "    \n",
    "    :param csv_file_path: Path to the CSV file. The file name (without extension) should match the table name.\n",
    "    :param server: SQL Server name or address.\n",
    "    :param database: Database name.\n",
    "    :param encoding: Encoding of the CSV file (default is 'utf-8').\n",
    "    \"\"\"\n",
    "    # Extract table name from the CSV file name\n",
    "    table_name = csv_file_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path, encoding=encoding)\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to decode {csv_file_path} with encoding '{encoding}'. Please try a different encoding.\")\n",
    "        return\n",
    "\n",
    "    # Drop rows with any null values\n",
    "    df.dropna(inplace=True)\n",
    "    conn_str = f\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};trusted_connection=yes;\"\n",
    "    \n",
    "    # Connect to the SQL Server\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Generate SQL INSERT query template\n",
    "    columns = ', '.join(df.columns)\n",
    "    placeholders = ', '.join(['?'] * len(df.columns))\n",
    "    insert_query = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "    \n",
    "    try:\n",
    "        # Insert each row into the table\n",
    "        for index, row in df.iterrows():\n",
    "            cursor.execute(insert_query, tuple(row))\n",
    "        \n",
    "        # Commit the transaction\n",
    "        conn.commit()\n",
    "        print(f\"Data from {csv_file_path} successfully inserted into {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data into {table_name}: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        cursor.close()\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from db_csv/KNS_Law.csv successfully inserted into KNS_Law\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = \"db_csv/KNS_Law.csv\"\n",
    "sqlserver = \"DESKTOP-9LFS960\\SQLEXPRESS\"\n",
    "database = \"BetaKnesset\"\n",
    "csv_to_ssms_table(csv_file_path, sqlserver, database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "with open('db_csv/KNS_Agenda.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
