{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af28f01",
   "metadata": {},
   "source": [
    "# Eval file between real and bots votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e26746dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV files...\n",
      "Loaded bot: 115 rows\n",
      "Loaded original: 116 rows\n",
      "\n",
      "Step 1: Normalized 116 english names (spaces ‚Üí underscores)\n",
      "Step 2: Converted responses - Pro: 69, Against: 46\n",
      "Step 3: Law passage analysis completed\n",
      "  bot: 69 pro, 46 against ‚Üí PASSED\n",
      "  original: 61 pro, 55 against ‚Üí PASSED\n",
      "  Agreement: YES\n",
      "Step 4: Found 41 mismatches\n",
      "\n",
      "\n",
      "============================================================\n",
      "MISMATCH LISTS BY CATEGORY\n",
      "============================================================\n",
      "\n",
      "üìã NAMES MISSING FROM bot (1 names):\n",
      "   (These names exist in original but not in bot)\n",
      "    1. Yasser_Hujirat\n",
      "\n",
      "üìã NAMES MISSING FROM original: None\n",
      "\n",
      "üó≥Ô∏è  VOTING DISAGREEMENTS (40 names):\n",
      "   (These names exist in both files but have different votes)\n",
      "    1. Moshe_Abutbul\n",
      "    2. Gadi_Eisenkot\n",
      "    3. Yisrael_Eichler\n",
      "    4. Zeev_Elkin\n",
      "    5. Moshe_Arbel\n",
      "    6. Yaakov_Asher\n",
      "    7. Debbie_Biton\n",
      "    8. Haim_Biton\n",
      "    9. Michael_Biton\n",
      "   10. David_Bitan\n",
      "   11. Vladimir_Beliak\n",
      "   12. Ram_Ben_Barak\n",
      "   13. Avraham_Betzalel\n",
      "   14. Mai_Golan\n",
      "   15. Moshe_Gafni\n",
      "   16. Simon_Davidson\n",
      "   17. Aryeh_Deri\n",
      "   18. Boaz_Toporovsky\n",
      "   19. Yosef_Tayeb\n",
      "   20. Hili_Trooper\n",
      "   21. Matan_Kahane\n",
      "   22. Ron_Katz\n",
      "   23. Miki_Levy\n",
      "   24. Naama_Lazimi\n",
      "   25. Yulia_Malinovsky\n",
      "   26. Micha_Malchieli\n",
      "   27. Uri_Maklev\n",
      "   28. Sharon_Nir\n",
      "   29. Orit_Struk\n",
      "   30. Gideon_Saar\n",
      "   31. Mansour_Abbas\n",
      "   32. Oded_Forer\n",
      "   33. Meir_Porush\n",
      "   34. Gilad_Kriv\n",
      "   35. Smicha_Rothman\n",
      "   36. Idan_Rol\n",
      "   37. Yoel_Razvozov\n",
      "   38. Efrat_Marom\n",
      "   39. Yifat_Shasha_Biton\n",
      "   40. Elazar_Stern\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "bot Result: PASSED (69 pro, 46 against)\n",
      "original Result: PASSED (61 pro, 55 against)\n",
      "Both files agree: YES\n",
      "Total mismatches: 41\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def normalize_english_names(df2):\n",
    "    \"\"\"\n",
    "    Step 1: Replace blank spaces with underscores in the english_name column of original\n",
    "    \n",
    "    Args:\n",
    "        df2: DataFrame from original\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with normalized english_name column\n",
    "    \"\"\"\n",
    "    df2_copy = df2.copy()\n",
    "    df2_copy['english_name'] = df2_copy['english_name'].str.replace(' ', '_')\n",
    "    print(f\"Step 1: Normalized {len(df2_copy)} english names (spaces ‚Üí underscores)\")\n",
    "    return df2_copy\n",
    "\n",
    "def convert_response_to_votes(df1):\n",
    "    \"\"\"\n",
    "    Step 2: Convert Hebrew Response column to voted_pro and voted_aginst columns\n",
    "    \n",
    "    Args:\n",
    "        df1: DataFrame from bot with Name and Response columns\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with added voted_pro and voted_aginst columns\n",
    "    \"\"\"\n",
    "    df1_copy = df1.copy()\n",
    "    \n",
    "    # Initialize the new columns\n",
    "    df1_copy['voted_pro'] = 0\n",
    "    df1_copy['voted_aginst'] = 0\n",
    "    \n",
    "    # Convert Hebrew responses\n",
    "    for idx, row in df1_copy.iterrows():\n",
    "        response = row['Response'].strip() if pd.notna(row['Response']) else ''\n",
    "        \n",
    "        if response == '◊ë◊¢◊ì':  # Pro/For\n",
    "            df1_copy.at[idx, 'voted_pro'] = 1\n",
    "            df1_copy.at[idx, 'voted_aginst'] = 0\n",
    "        elif response == '◊†◊í◊ì':  # Against\n",
    "            df1_copy.at[idx, 'voted_pro'] = 0\n",
    "            df1_copy.at[idx, 'voted_aginst'] = 1\n",
    "        else:\n",
    "            # Handle unexpected values - set both to 0\n",
    "            df1_copy.at[idx, 'voted_pro'] = 0\n",
    "            df1_copy.at[idx, 'voted_aginst'] = 0\n",
    "            if response:  # Only warn if there's actually a value\n",
    "                print(f\"Warning: Unexpected response '{response}' for {row['Name']}\")\n",
    "    \n",
    "    pro_count = df1_copy['voted_pro'].sum()\n",
    "    against_count = df1_copy['voted_aginst'].sum()\n",
    "    print(f\"Step 2: Converted responses - Pro: {pro_count}, Against: {against_count}\")\n",
    "    \n",
    "    return df1_copy\n",
    "\n",
    "def analyze_law_passage(df1_converted, df2_normalized):\n",
    "    \"\"\"\n",
    "    Step 3: Analyze if the law passed in both CSVs (more voted_pro than voted_aginst)\n",
    "    \n",
    "    Args:\n",
    "        df1_converted: bot with converted vote columns\n",
    "        df2_normalized: original with normalized names\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with analysis results\n",
    "    \"\"\"\n",
    "    # bot analysis\n",
    "    bot_pro = df1_converted['voted_pro'].sum()\n",
    "    bot_against = df1_converted['voted_aginst'].sum()\n",
    "    bot_passed = bot_pro > bot_against\n",
    "    \n",
    "    # original analysis\n",
    "    original_pro = df2_normalized['voted_pro'].sum()\n",
    "    original_against = df2_normalized['voted_aginst'].sum()\n",
    "    original_passed = original_pro > original_against\n",
    "    \n",
    "    # Agreement check\n",
    "    both_agree = bot_passed == original_passed\n",
    "    \n",
    "    results = {\n",
    "        'bot': {\n",
    "            'pro_votes': int(bot_pro),\n",
    "            'against_votes': int(bot_against),\n",
    "            'total_votes': len(df1_converted),\n",
    "            'law_passed': bot_passed\n",
    "        },\n",
    "        'original': {\n",
    "            'pro_votes': int(original_pro),\n",
    "            'against_votes': int(original_against),\n",
    "            'total_votes': len(df2_normalized),\n",
    "            'law_passed': original_passed\n",
    "        },\n",
    "        'agreement': {\n",
    "            'both_agree_on_result': both_agree,\n",
    "            'both_passed': bot_passed and original_passed,\n",
    "            'both_failed': not bot_passed and not original_passed\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"Step 3: Law passage analysis completed\")\n",
    "    print(f\"  bot: {bot_pro} pro, {bot_against} against ‚Üí {'PASSED' if bot_passed else 'FAILED'}\")\n",
    "    print(f\"  original: {original_pro} pro, {original_against} against ‚Üí {'PASSED' if original_passed else 'FAILED'}\")\n",
    "    print(f\"  Agreement: {'YES' if both_agree else 'NO'}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def find_mismatches(df1_converted, df2_normalized):\n",
    "    \"\"\"\n",
    "    Step 4: Find and print mismatches between the two files for the same names\n",
    "    \n",
    "    Args:\n",
    "        df1_converted: bot with converted vote columns\n",
    "        df2_normalized: original with normalized names\n",
    "    \n",
    "    Returns:\n",
    "        List of mismatch details\n",
    "    \"\"\"\n",
    "    mismatches = []\n",
    "    \n",
    "    # Create lookup dictionary for original using english_name as key\n",
    "    original_lookup = {}\n",
    "    for _, row in df2_normalized.iterrows():\n",
    "        original_lookup[row['english_name']] = {\n",
    "            'voted_pro': row['voted_pro'],\n",
    "            'voted_aginst': row['voted_aginst']\n",
    "        }\n",
    "    \n",
    "    # Check each person in bot\n",
    "    for _, row1 in df1_converted.iterrows():\n",
    "        name = row1['Name']\n",
    "        \n",
    "        if name in original_lookup:\n",
    "            original_data = original_lookup[name]\n",
    "            \n",
    "            # Compare votes\n",
    "            bot_pro = row1['voted_pro']\n",
    "            bot_against = row1['voted_aginst']\n",
    "            original_pro = original_data['voted_pro']\n",
    "            original_against = original_data['voted_aginst']\n",
    "            \n",
    "            # Check for mismatches\n",
    "            if bot_pro != original_pro or bot_against != original_against:\n",
    "                mismatch = {\n",
    "                    'name': name,\n",
    "                    'bot_pro': bot_pro,\n",
    "                    'bot_against': bot_against,\n",
    "                    'original_pro': original_pro,\n",
    "                    'original_against': original_against,\n",
    "                    'differences': []\n",
    "                }\n",
    "                \n",
    "                if bot_pro != original_pro:\n",
    "                    mismatch['differences'].append(f\"Pro votes: bot={bot_pro}, original={original_pro}\")\n",
    "                if bot_against != original_against:\n",
    "                    mismatch['differences'].append(f\"Against votes: bot={bot_against}, original={original_against}\")\n",
    "                \n",
    "                mismatches.append(mismatch)\n",
    "        else:\n",
    "            # Name in bot but not in original\n",
    "            mismatch = {\n",
    "                'name': name,\n",
    "                'bot_pro': row1['voted_pro'],\n",
    "                'bot_against': row1['voted_aginst'],\n",
    "                'original_pro': 'NOT_FOUND',\n",
    "                'original_against': 'NOT_FOUND',\n",
    "                'differences': ['Name exists in bot but not in original']\n",
    "            }\n",
    "            mismatches.append(mismatch)\n",
    "    \n",
    "    # Check for names in original but not in bot\n",
    "    bot_names = set(df1_converted['Name'])\n",
    "    for english_name in original_lookup.keys():\n",
    "        if english_name not in bot_names:\n",
    "            original_data = original_lookup[english_name]\n",
    "            mismatch = {\n",
    "                'name': english_name,\n",
    "                'bot_pro': 'NOT_FOUND',\n",
    "                'bot_against': 'NOT_FOUND',\n",
    "                'original_pro': original_data['voted_pro'],\n",
    "                'original_against': original_data['voted_aginst'],\n",
    "                'differences': ['Name exists in original but not in bot']\n",
    "            }\n",
    "            mismatches.append(mismatch)\n",
    "    \n",
    "    print(f\"Step 4: Found {len(mismatches)} mismatches\")\n",
    "    return mismatches\n",
    "\n",
    "def categorize_mismatches(mismatches):\n",
    "    \"\"\"\n",
    "    Categorize mismatches into different types\n",
    "    \n",
    "    Args:\n",
    "        mismatches: List of mismatch dictionaries from find_mismatches()\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with categorized mismatches\n",
    "    \"\"\"\n",
    "    missing_from_bot = []  # Names in original but not in bot\n",
    "    missing_from_original = []  # Names in bot but not in original\n",
    "    voting_disagreements = []  # Names in both files but with different votes\n",
    "    \n",
    "    for mismatch in mismatches:\n",
    "        if mismatch['bot_pro'] == 'NOT_FOUND':\n",
    "            missing_from_bot.append(mismatch['name'])\n",
    "        elif mismatch['original_pro'] == 'NOT_FOUND':\n",
    "            missing_from_original.append(mismatch['name'])\n",
    "        else:\n",
    "            voting_disagreements.append(mismatch['name'])\n",
    "    \n",
    "    return {\n",
    "        'missing_from_bot': missing_from_bot,\n",
    "        'missing_from_original': missing_from_original,\n",
    "        'voting_disagreements': voting_disagreements\n",
    "    }\n",
    "\n",
    "def print_mismatch_lists(categorized_mismatches):\n",
    "    \"\"\"\n",
    "    Print organized lists of mismatched names by category\n",
    "    \n",
    "    Args:\n",
    "        categorized_mismatches: Dictionary from categorize_mismatches()\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"MISMATCH LISTS BY CATEGORY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Names missing from bot (exist in original only)\n",
    "    missing_bot = categorized_mismatches['missing_from_bot']\n",
    "    if missing_bot:\n",
    "        print(f\"\\nüìã NAMES MISSING FROM bot ({len(missing_bot)} names):\")\n",
    "        print(\"   (These names exist in original but not in bot)\")\n",
    "        for i, name in enumerate(missing_bot, 1):\n",
    "            print(f\"   {i:2d}. {name}\")\n",
    "    else:\n",
    "        print(f\"\\nüìã NAMES MISSING FROM bot: None\")\n",
    "    \n",
    "    # Names missing from original (exist in bot only)\n",
    "    missing_original = categorized_mismatches['missing_from_original']\n",
    "    if missing_original:\n",
    "        print(f\"\\nüìã NAMES MISSING FROM original ({len(missing_original)} names):\")\n",
    "        print(\"   (These names exist in bot but not in original)\")\n",
    "        for i, name in enumerate(missing_original, 1):\n",
    "            print(f\"   {i:2d}. {name}\")\n",
    "    else:\n",
    "        print(f\"\\nüìã NAMES MISSING FROM original: None\")\n",
    "    \n",
    "    # Names with voting disagreements\n",
    "    disagreements = categorized_mismatches['voting_disagreements']\n",
    "    if disagreements:\n",
    "        print(f\"\\nüó≥Ô∏è  VOTING DISAGREEMENTS ({len(disagreements)} names):\")\n",
    "        print(\"   (These names exist in both files but have different votes)\")\n",
    "        for i, name in enumerate(disagreements, 1):\n",
    "            print(f\"   {i:2d}. {name}\")\n",
    "    else:\n",
    "        print(f\"\\nüó≥Ô∏è  VOTING DISAGREEMENTS: None\")\n",
    "\n",
    "\n",
    "def main(bot_path, original_path):\n",
    "    \"\"\"\n",
    "    Main function that executes all steps\n",
    "    \"\"\"\n",
    "    # File paths - update these with your actual file paths\n",
    "         \n",
    "    try:\n",
    "        # Load the CSV files\n",
    "        print(\"Loading CSV files...\")\n",
    "        df1 = pd.read_csv(bot_path)\n",
    "        df2 = pd.read_csv(original_path)\n",
    "        \n",
    "        # Clean column names (remove extra whitespace)\n",
    "        df1.columns = df1.columns.str.strip()\n",
    "        df2.columns = df2.columns.str.strip()\n",
    "        \n",
    "        print(f\"Loaded bot: {df1.shape[0]} rows\")\n",
    "        print(f\"Loaded original: {df2.shape[0]} rows\")\n",
    "        print()\n",
    "        \n",
    "        # Step 1: Normalize english names in original\n",
    "        df2_normalized = normalize_english_names(df2)\n",
    "        \n",
    "        # Step 2: Convert Response to vote columns in bot\n",
    "        df1_converted = convert_response_to_votes(df1)\n",
    "        \n",
    "        # Step 3: Analyze law passage\n",
    "        analysis_results = analyze_law_passage(df1_converted, df2_normalized)\n",
    "        \n",
    "        # Step 4: Find mismatches\n",
    "        mismatches = find_mismatches(df1_converted, df2_normalized)\n",
    "        \n",
    "        # Categorize mismatches\n",
    "        categorized_mismatches = categorize_mismatches(mismatches)\n",
    "        \n",
    "        # Print ALL mismatched names first\n",
    "        print()\n",
    "        # print_all_mismatched_names(categorized_mismatches)\n",
    "        \n",
    "        # Print the organized mismatch lists by category\n",
    "        print()\n",
    "        print_mismatch_lists(categorized_mismatches)\n",
    "        \n",
    "        # Print the detailed mismatch report\n",
    "        print()\n",
    "        # print_mismatches(mismatches)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"=\" * 60)\n",
    "        print(\"SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"bot Result: {'PASSED' if analysis_results['bot']['law_passed'] else 'FAILED'} \"\n",
    "              f\"({analysis_results['bot']['pro_votes']} pro, {analysis_results['bot']['against_votes']} against)\")\n",
    "        print(f\"original Result: {'PASSED' if analysis_results['original']['law_passed'] else 'FAILED'} \"\n",
    "              f\"({analysis_results['original']['pro_votes']} pro, {analysis_results['original']['against_votes']} against)\")\n",
    "        print(f\"Both files agree: {'YES' if analysis_results['agreement']['both_agree_on_result'] else 'NO'}\")\n",
    "        print(f\"Total mismatches: {len(mismatches)}\")\n",
    "        \n",
    "        return analysis_results, mismatches, categorized_mismatches\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find CSV file - {e}\")\n",
    "        print(\"Please make sure both CSV files exist and update the file paths in the main() function.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bot_path = \"../../src/◊ó◊ï◊ß ◊ú◊™◊ô◊ß◊ï◊ü ◊§◊ß◊ï◊ì◊™ ◊î◊û◊©◊ò◊®◊î (◊û◊°' 37)_res.csv\"\n",
    "    original_path = \"../laws/◊ó◊ï◊ß ◊ú◊™◊ô◊ß◊ï◊ü ◊§◊ß◊ï◊ì◊™ ◊î◊û◊©◊ò◊®◊î (◊û◊°' 37).csv\" \n",
    "    main(bot_path, original_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c650c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "def load_name_mapping(mapping_file_path: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Load the Hebrew to English name mapping from CSV file.\n",
    "    \n",
    "    Args:\n",
    "        mapping_file_path: Path to the names_mapping.csv file\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping Hebrew names to English names\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(mapping_file_path, encoding='utf-8')\n",
    "        return dict(zip(df['name'], df['english_name']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading mapping file: {e}\")\n",
    "        return {}\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a name by removing extra spaces and special characters.\n",
    "    \n",
    "    Args:\n",
    "        name: Name to normalize\n",
    "    \n",
    "    Returns:\n",
    "        Normalized name\n",
    "    \"\"\"\n",
    "    if pd.isna(name) or not isinstance(name, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove extra whitespace and normalize\n",
    "    normalized = ' '.join(name.strip().split())\n",
    "    return normalized\n",
    "\n",
    "def reverse_hebrew_name_order(hebrew_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert Hebrew name from \"last name, first name\" to \"first name last name\" format.\n",
    "    This helps with matching when the raw data has names in different order.\n",
    "    \n",
    "    Args:\n",
    "        hebrew_name: Hebrew name in any format\n",
    "    \n",
    "    Returns:\n",
    "        Hebrew name in \"first name last name\" format\n",
    "    \"\"\"\n",
    "    if not hebrew_name or not isinstance(hebrew_name, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # If there's a comma, it's likely \"last, first\" format\n",
    "    if ',' in hebrew_name:\n",
    "        parts = [part.strip() for part in hebrew_name.split(',')]\n",
    "        if len(parts) == 2:\n",
    "            return f\"{parts[1]} {parts[0]}\"  # Reverse to \"first last\"\n",
    "    \n",
    "    return hebrew_name\n",
    "\n",
    "def find_best_match(target_name: str, mapping_dict: Dict[str, str]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Find the best match for a target name in the mapping dictionary.\n",
    "    Tries multiple strategies including exact match, reversed order, and partial matching.\n",
    "    \n",
    "    Args:\n",
    "        target_name: Name to find match for\n",
    "        mapping_dict: Dictionary of Hebrew to English names\n",
    "    \n",
    "    Returns:\n",
    "        English name if match found, None otherwise\n",
    "    \"\"\"\n",
    "    if not target_name:\n",
    "        return None\n",
    "    \n",
    "    target_normalized = normalize_name(target_name)\n",
    "    \n",
    "    # Strategy 1: Exact match\n",
    "    if target_normalized in mapping_dict:\n",
    "        return mapping_dict[target_normalized]\n",
    "    \n",
    "    # Strategy 2: Try reversed order (for \"last, first\" format)\n",
    "    target_reversed = reverse_hebrew_name_order(target_normalized)\n",
    "    if target_reversed in mapping_dict:\n",
    "        return mapping_dict[target_reversed]\n",
    "    \n",
    "    # Strategy 3: Check all keys with different normalizations\n",
    "    for hebrew_name, english_name in mapping_dict.items():\n",
    "        hebrew_normalized = normalize_name(hebrew_name)\n",
    "        hebrew_reversed = reverse_hebrew_name_order(hebrew_normalized)\n",
    "        \n",
    "        if (target_normalized == hebrew_normalized or \n",
    "            target_normalized == hebrew_reversed or\n",
    "            target_reversed == hebrew_normalized):\n",
    "            return english_name\n",
    "    \n",
    "    # Strategy 4: Partial matching (if names contain same words)\n",
    "    target_words = set(target_normalized.split())\n",
    "    if len(target_words) > 1:  # Only for multi-word names\n",
    "        for hebrew_name, english_name in mapping_dict.items():\n",
    "            hebrew_words = set(normalize_name(hebrew_name).split())\n",
    "            # If most words match\n",
    "            if len(target_words.intersection(hebrew_words)) >= len(target_words) - 1:\n",
    "                return english_name\n",
    "    \n",
    "    return None\n",
    "\n",
    "def process_voting_data(raw_data_df: pd.DataFrame, \n",
    "                       mapping_file_path: str,\n",
    "                       hebrew_name_column: str = 'name',\n",
    "                       voted_pro_values: List[str] = None,\n",
    "                       voted_against_values: List[str] = None) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Process voting data by mapping Hebrew names to English and adding voting columns.\n",
    "    \n",
    "    Args:\n",
    "        raw_data_df: DataFrame containing the raw voting data\n",
    "        mapping_file_path: Path to the names_mapping.csv file\n",
    "        hebrew_name_column: Name of column containing Hebrew names\n",
    "        voted_pro_values: List of values that indicate \"voted pro\" (e.g., ['◊ë◊¢◊ì', '◊õ◊ü'])\n",
    "        voted_against_values: List of values that indicate \"voted against\" (e.g., ['◊†◊í◊ì', '◊ú◊ê'])\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (processed_dataframe, list_of_unmatched_names)\n",
    "    \"\"\"\n",
    "    if voted_pro_values is None:\n",
    "        voted_pro_values = ['◊ë◊¢◊ì', '◊õ◊ü', 'pro', 'yes', 'voted_pro']\n",
    "    \n",
    "    if voted_against_values is None:\n",
    "        voted_against_values = ['◊†◊í◊ì', '◊ú◊ê', 'against', 'no', 'voted_against']\n",
    "    \n",
    "    # Load the mapping\n",
    "    name_mapping = load_name_mapping(mapping_file_path)\n",
    "    if not name_mapping:\n",
    "        raise ValueError(\"Could not load name mapping file\")\n",
    "    \n",
    "    # Create a copy of the dataframe\n",
    "    df = raw_data_df.copy()\n",
    "    \n",
    "    # Add new columns\n",
    "    df['english_name'] = ''\n",
    "    df['voted_pro'] = ''\n",
    "    df['voted_against'] = ''\n",
    "    \n",
    "    unmatched_names = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        hebrew_name = row[hebrew_name_column] if hebrew_name_column in df.columns else ''\n",
    "        \n",
    "        # Find English name match\n",
    "        english_name = find_best_match(hebrew_name, name_mapping)\n",
    "        \n",
    "        if english_name:\n",
    "            df.at[idx, 'english_name'] = english_name\n",
    "            \n",
    "            # Process voting columns - check all columns for voting indicators\n",
    "            for col in df.columns:\n",
    "                if col not in [hebrew_name_column, 'english_name', 'voted_pro', 'voted_against']:\n",
    "                    cell_value = str(row[col]).strip() if pd.notna(row[col]) else ''\n",
    "                    \n",
    "                    # Check for pro votes\n",
    "                    if any(pro_val in cell_value for pro_val in voted_pro_values):\n",
    "                        current_pro = df.at[idx, 'voted_pro']\n",
    "                        df.at[idx, 'voted_pro'] = f\"{current_pro}, {col}\" if current_pro else col\n",
    "                    \n",
    "                    # Check for against votes  \n",
    "                    if any(against_val in cell_value for against_val in voted_against_values):\n",
    "                        current_against = df.at[idx, 'voted_against']\n",
    "                        df.at[idx, 'voted_against'] = f\"{current_against}, {col}\" if current_against else col\n",
    "        else:\n",
    "            unmatched_names.append(hebrew_name)\n",
    "            df.at[idx, 'english_name'] = 'UNMATCHED'\n",
    "    \n",
    "    return df, unmatched_names\n",
    "\n",
    "def analyze_voting_patterns(processed_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a summary analysis of voting patterns.\n",
    "    \n",
    "    Args:\n",
    "        processed_df: DataFrame processed by process_voting_data\n",
    "    \n",
    "    Returns:\n",
    "        Summary DataFrame with voting statistics\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    for idx, row in processed_df.iterrows():\n",
    "        hebrew_name = row.get('name', '') if 'name' in processed_df.columns else row.iloc[0]\n",
    "        english_name = row['english_name']\n",
    "        voted_pro = row['voted_pro']\n",
    "        voted_against = row['voted_against']\n",
    "        \n",
    "        pro_count = len([x for x in voted_pro.split(',') if x.strip()]) if voted_pro else 0\n",
    "        against_count = len([x for x in voted_against.split(',') if x.strip()]) if voted_against else 0\n",
    "        \n",
    "        summary_data.append({\n",
    "            'hebrew_name': hebrew_name,\n",
    "            'english_name': english_name,\n",
    "            'voted_pro_count': pro_count,\n",
    "            'voted_against_count': against_count,\n",
    "            'voted_pro_on': voted_pro,\n",
    "            'voted_against_on': voted_against,\n",
    "            'total_votes': pro_count + against_count,\n",
    "            'match_status': 'Matched' if english_name != 'UNMATCHED' else 'Unmatched'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(summary_data)\n",
    "\n",
    "# Example usage function\n",
    "def main_processing_example():\n",
    "    \"\"\"\n",
    "    Example of how to use the functions above.\n",
    "    Replace with your actual file paths and data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Example: Load your raw data (replace with actual file path)\n",
    "    raw_data = pd.read_csv('your_raw_voting_data.csv')\n",
    "    \n",
    "    # Process the data\n",
    "    processed_data, unmatched = process_voting_data(\n",
    "        raw_data_df=raw_data,\n",
    "        mapping_file_path='names_mapping.csv',\n",
    "        hebrew_name_column='name',  # adjust column name as needed\n",
    "        voted_pro_values=['◊ë◊¢◊ì', '◊õ◊ü', 'pro'],\n",
    "        voted_against_values=['◊†◊í◊ì', '◊ú◊ê', 'against']\n",
    "    )\n",
    "    \n",
    "    # Print unmatched names\n",
    "    if unmatched:\n",
    "        print(\"Unmatched names:\")\n",
    "        for name in unmatched:\n",
    "            print(f\"  - {name}\")\n",
    "    else:\n",
    "        print(\"All names were successfully matched!\")\n",
    "    \n",
    "    # Create voting analysis\n",
    "    voting_summary = analyze_voting_patterns(processed_data)\n",
    "    \n",
    "    # Save results\n",
    "    processed_data.to_csv('processed_voting_data.csv', index=False, encoding='utf-8')\n",
    "    voting_summary.to_csv('voting_summary.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    print(\"Functions are ready to use. Uncomment and modify the example code above.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_processing_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
