{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_ip = '34.0.64.248:9200'\n",
    "kibana_ip = '34.0.64.248:5601'\n",
    "es_username = 'user'\n",
    "es_password = 'knesset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection, CollectionSchema, FieldSchema, DataType, connections, utility\n",
    "from sentence_transformers import SentenceTransformer\n",
    "#from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "#load_dotenv()\n",
    "milvus_host = \"localhost\"\n",
    "milvus_port = 19530\n",
    "connections.connect(\"default\", host=milvus_host, port=milvus_port)\n",
    "\n",
    "# Check the model output dimension\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "dimension = model.get_sentence_embedding_dimension()\n",
    "\n",
    "def vector_db(docs, collection_name=\"demo\"):\n",
    "    # Drop the collection if it exists\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "\n",
    "    fields = [\n",
    "        FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True),\n",
    "        FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=dimension),\n",
    "        FieldSchema(name=\"content\", dtype=DataType.VARCHAR, max_length=500)  # Adding content field for storage\n",
    "    ]\n",
    "\n",
    "    schema = CollectionSchema(fields=fields, enable_dynamic_field=True)\n",
    "    demo = Collection(collection_name, schema=schema)\n",
    "\n",
    "    index_params = {\n",
    "        \"index_type\": \"IVF_FLAT\",\n",
    "        \"metric_type\": \"COSINE\",\n",
    "        \"params\": {\"nlist\": 128}\n",
    "    }\n",
    "\n",
    "    demo.create_index(\n",
    "        field_name=\"vector\",\n",
    "        index_params=index_params\n",
    "    )\n",
    "\n",
    "    ids = []\n",
    "    vectors = []\n",
    "    contents = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        if isinstance(doc, str):\n",
    "            text_content = doc  # Directly use the document content if it's already a string\n",
    "        else:\n",
    "            text_content = doc.page_content  # Assuming doc has a 'page_content' attribute or similar\n",
    "        \n",
    "        embeddings = model.encode(text_content)\n",
    "        vector = embeddings.tolist()\n",
    "        ids.append(i)\n",
    "        vectors.append(vector)\n",
    "        contents.append(text_content)  # Store the document content\n",
    "       # print(f\"Document {i}: {text_content}\")\n",
    "       # print(f\"Vector: {vector[:5]}...\")  # Print first 5 dimensions for brevity\n",
    "\n",
    "    # Insert the data as separate lists for each field\n",
    "    demo.insert([ids, vectors, contents])\n",
    "\n",
    "    return demo\n",
    "\n",
    "    # Return a callable retriever\n",
    "def retriever(query, demo):\n",
    "    if isinstance(query, dict) and 'question' in query:\n",
    "        query = query['question']\n",
    "    elif not isinstance(query, str):\n",
    "        raise ValueError(f\"Unexpected query format: {query}\")\n",
    "\n",
    "    # Encode the query and perform a search on the collection\n",
    "    query_embedding = model.encode(query).tolist()\n",
    "    search_params = {\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 10}}\n",
    "    results = demo.search([query_embedding], \"vector\", param=search_params, limit=20, output_fields=[\"id\", \"content\"])\n",
    "    \n",
    "    # Check search results\n",
    "    #print(\"Search results:\", results)\n",
    "    \n",
    "    # Fetch detailed content of the results\n",
    "    search_results = []\n",
    "    if results:\n",
    "        for result in results[0]:\n",
    "            entity = demo.query(expr=f\"id == {result.id}\", output_fields=[\"id\", \"content\"])\n",
    "            if entity:\n",
    "                search_results.append(entity[0]['content'])\n",
    "            #print(f\"Entity for id {result.id}:\", entity)\n",
    "\n",
    "    return search_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import re\n",
    "\n",
    "def retrive_quotes(KNS_name):\n",
    "\n",
    "    es = Elasticsearch(f'http://{elastic_ip}', basic_auth=(es_username, es_password), request_timeout=500)\n",
    "    data_q =[]\n",
    "    # Query definition\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\"match\": {\"speaker_name\": KNS_name}}\n",
    "                ],\n",
    "                \"filter\": {\n",
    "                    \"script\": {\n",
    "                        \"script\": {\n",
    "                            \"source\": \"doc['sentence_text.keyword'].size() > 0 && doc['sentence_text.keyword'].value.length() > 20\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Initialize scroll\n",
    "    resp = es.search(index=\"all_features_sentences\", body=query, scroll=\"2m\", size=1000)\n",
    "\n",
    "    # Retrieve the scroll ID and first batch of hits\n",
    "    scroll_id = resp['_scroll_id']\n",
    "    hits = resp['hits']['hits']\n",
    "\n",
    "    total_hits = 0\n",
    "    while total_hits<4000:\n",
    "        for hit in hits:\n",
    "            data_q.append(\"%(sentence_text)s\" % hit[\"_source\"])\n",
    "        #print(\"%(sentence_text)s\" % hit[\"_source\"])\n",
    "\n",
    "        total_hits += len(hits)\n",
    "\n",
    "        # Fetch the next batch\n",
    "        resp = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = resp['_scroll_id']\n",
    "        hits = resp['hits']['hits']\n",
    "\n",
    "    print(f\"Total results retrieved: {total_hits}\")\n",
    "\n",
    "    # Clear the scroll to free resources\n",
    "    es.clear_scroll(scroll_id=scroll_id)\n",
    "    for i in range(len(data_q)):\n",
    "        data_q[i] = re.sub(r'[^א-ת ]', '', data_q[i]).strip()\n",
    "\n",
    "    return data_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_11684\\1370633807.py:27: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  resp = es.search(index=\"all_features_sentences\", body=query, scroll=\"2m\", size=1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results retrieved: 4000\n"
     ]
    }
   ],
   "source": [
    "docs = retrive_quotes(\"מירי רגב\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = vector_db(docs, collection_name=\"Miri_Regev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Miri_Regev']\n"
     ]
    }
   ],
   "source": [
    "collections = utility.list_collections()\n",
    "print(collections)\n",
    "\n",
    "M = Collection(name=\"Miri_Regev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: עם רכבת שראש הממשלה אישר מקריית שמונה ועד אילת אנחנו נביא גם להקלה בפקקים גם לפיזור תעסוקה גם לפיזור האוכלוסייה וזה יביא מזור אמיתי למדינת ישראל\n",
      "Content: הקבלן כן שבעצם מדינת ישראל היא מי ששוכרת שירותי קבלן\n",
      "Content: ואת זה רואה הציבור הישראלי\n",
      "Content: אין ספק שיש חשיבות גדולה שחברות תעופה ישראליות יחזרו משום שהתעופה נותנת מענה לא רק לענף התעופה אלא לענפים נרחבים שהם נגזרות של ענף התעופה סוכני נסיעות בתי מלון מסעדות היסעים פרטיים ועוד ועוד\n",
      "Content: הנחיתי הבוקר את מנהל רשות התחבורה הציבורית ורכבת ישראל לתגבר את התחבורה הציבורית לאזור ההלוויה ההמונית ולתגבר את הקווים הביןעירוניים לבני ברק כדי לאפשר להמונים להגיע ולקחת חלק בהלוויה\n",
      "Content: לתחבורה הציבורית\n",
      "Content: דרום תל אביב תקבל הנחה של  בתחבורה הציבורית\n",
      "Content: אזרחי מדינת ישראל אנו ממשלת ישראל פועלים יוםיום בהובלתו של ראש הממשלה נתניהו לאפשר לכם רשת ביטחון בריאותית וכלכלית\n",
      "Content: זו תוכנית גרנדיוזית שבסופו של דבר מחברת את מדינת ישראל גם לאורך וגם לרוחב\n",
      "Content: והתחבורה הציבורית ב\n",
      "Content: שיקבל החלטות טובות למען כלל הציבור הישראלי\n",
      "Content: אזרחי ישראל\n",
      "Content: זו בשורה אדירה לאזרחי מדינת ישראל שאדם שגר בקריית שמונה יוכל לעבוד בתל אביב ושאדם שגר בתל אביב יוכל לעבודה בדימונה ולנסוע ממקום למקום\n",
      "Content: אז אני מודיעה לכם אם מחר אתם תחסמו את נתבג ולא תאפשרו לאזרחי ישראל לנסוע כמו שצריך לטוס כמו שצריך ולחזור בשלום הביתה אני מודיעה לכם שאתם אלה שתצטרכו לשפות אותם  כי אנחנו לא נשפה את אזרחי מדינת ישראל\n",
      "Content: ואני מודיעה לכם שאתם אם תלכו הביתה ומהר כי הציבור הישראלי רואה לכם\n",
      "Content: לכן אני אומרת לך יש מצוקות תחבורתיות למדינת ישראל בגלל השטח שלה\n",
      "Content: כך אתה נוהג גם בוועדות הכנסת השונות ואני מאוד מאוד מעריכה ושמחה שאתה הוא שמייצג את משרד התחבורה כאן בכנסת ישראל  ולא רק בכנסת בהרבה מאוד פורומים\n",
      "Content: הציבור הישראלי יוכל ליהנות בעתיד הקרוב מקווי אקספרס שאנחנו מקדמים קווים שיובילו את הישראלים מנתבג לאבו דאבי בתוך שלוש שעות בלבד\n",
      "Content: אבל כמו שאמרתי הציבור הישראלי רואה  הציבור הישראלי שלא יכול להסתובב ברחובות הציבור הישראלי שמרגיש פחד\n",
      "Content: ככה תיראה מדינת ישראל\n",
      "['עם רכבת שראש הממשלה אישר מקריית שמונה ועד אילת אנחנו נביא גם להקלה בפקקים גם לפיזור תעסוקה גם לפיזור האוכלוסייה וזה יביא מזור אמיתי למדינת ישראל', 'הקבלן כן שבעצם מדינת ישראל היא מי ששוכרת שירותי קבלן', 'ואת זה רואה הציבור הישראלי', 'אין ספק שיש חשיבות גדולה שחברות תעופה ישראליות יחזרו משום שהתעופה נותנת מענה לא רק לענף התעופה אלא לענפים נרחבים שהם נגזרות של ענף התעופה סוכני נסיעות בתי מלון מסעדות היסעים פרטיים ועוד ועוד', 'הנחיתי הבוקר את מנהל רשות התחבורה הציבורית ורכבת ישראל לתגבר את התחבורה הציבורית לאזור ההלוויה ההמונית ולתגבר את הקווים הביןעירוניים לבני ברק כדי לאפשר להמונים להגיע ולקחת חלק בהלוויה', 'לתחבורה הציבורית', 'דרום תל אביב תקבל הנחה של  בתחבורה הציבורית', 'אזרחי מדינת ישראל אנו ממשלת ישראל פועלים יוםיום בהובלתו של ראש הממשלה נתניהו לאפשר לכם רשת ביטחון בריאותית וכלכלית', 'זו תוכנית גרנדיוזית שבסופו של דבר מחברת את מדינת ישראל גם לאורך וגם לרוחב', 'והתחבורה הציבורית ב', 'שיקבל החלטות טובות למען כלל הציבור הישראלי', 'אזרחי ישראל', 'זו בשורה אדירה לאזרחי מדינת ישראל שאדם שגר בקריית שמונה יוכל לעבוד בתל אביב ושאדם שגר בתל אביב יוכל לעבודה בדימונה ולנסוע ממקום למקום', 'אז אני מודיעה לכם אם מחר אתם תחסמו את נתבג ולא תאפשרו לאזרחי ישראל לנסוע כמו שצריך לטוס כמו שצריך ולחזור בשלום הביתה אני מודיעה לכם שאתם אלה שתצטרכו לשפות אותם  כי אנחנו לא נשפה את אזרחי מדינת ישראל', 'ואני מודיעה לכם שאתם אם תלכו הביתה ומהר כי הציבור הישראלי רואה לכם', 'לכן אני אומרת לך יש מצוקות תחבורתיות למדינת ישראל בגלל השטח שלה', 'כך אתה נוהג גם בוועדות הכנסת השונות ואני מאוד מאוד מעריכה ושמחה שאתה הוא שמייצג את משרד התחבורה כאן בכנסת ישראל  ולא רק בכנסת בהרבה מאוד פורומים', 'הציבור הישראלי יוכל ליהנות בעתיד הקרוב מקווי אקספרס שאנחנו מקדמים קווים שיובילו את הישראלים מנתבג לאבו דאבי בתוך שלוש שעות בלבד', 'אבל כמו שאמרתי הציבור הישראלי רואה  הציבור הישראלי שלא יכול להסתובב ברחובות הציבור הישראלי שמרגיש פחד', 'ככה תיראה מדינת ישראל']\n"
     ]
    }
   ],
   "source": [
    "M.load()\n",
    "results = retriever({\"question\": \"מה דעתך על תחבורה ציבורית בישראל?\"}, M)\n",
    "for result in results:\n",
    "    print(f\"Content: {result}\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "import os\n",
    "prompt = (\"\"\"\n",
    "            The following are quotes by Miri Regev:\\n{context_text}\\n\\n\"\n",
    "            \"Based on the above quotes, answer the following question like you were Miri Regev, with her tone and common words\\phrases she said! answer only to the question, do not show your thinking process.:\\n{user_input}\n",
    "          \"\"\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_11684\\2863314309.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "            {\"context\": {\"retriever\": retriever_callable}, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
