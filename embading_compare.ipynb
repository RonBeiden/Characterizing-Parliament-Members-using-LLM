{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymilvus==2.4.13 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.4.13)\n",
      "Requirement already satisfied: setuptools>69 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus==2.4.13) (75.6.0)\n",
      "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus==2.4.13) (1.67.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus==2.4.13) (3.20.3)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus==2.4.13) (1.0.1)\n",
      "Requirement already satisfied: ujson>=2.0.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus==2.4.13) (5.10.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymilvus==2.4.13) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2.4->pymilvus==2.4.13) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2.4->pymilvus==2.4.13) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2.4->pymilvus==2.4.13) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2.4->pymilvus==2.4.13) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus==2.4.13) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -elenium (c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -elenium (c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pymilvus==2.4.13\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections\n",
    "\n",
    "try:\n",
    "    connections.connect(alias=\"default\", host=\"127.0.0.1\", port=\"19530\")\n",
    "    print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch\n",
      "  Downloading elasticsearch-8.17.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting elastic-transport<9,>=8.15.1 (from elasticsearch)\n",
      "  Downloading elastic_transport-8.15.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (1.26.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2021.10.8)\n",
      "Downloading elasticsearch-8.17.0-py3-none-any.whl (571 kB)\n",
      "   ---------------------------------------- 0.0/571.2 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/571.2 kB 1.3 MB/s eta 0:00:01\n",
      "   ----- --------------------------------- 81.9/571.2 kB 919.0 kB/s eta 0:00:01\n",
      "   -------- ----------------------------- 133.1/571.2 kB 871.5 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 235.5/571.2 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 337.9/571.2 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 378.9/571.2 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  563.2/571.2 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 571.2/571.2 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading elastic_transport-8.15.1-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.4/64.4 kB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: elastic-transport, elasticsearch\n",
      "Successfully installed elastic-transport-8.15.1 elasticsearch-8.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -elenium (c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -elenium (c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "elastic_ip = '34.0.64.248:9200'\n",
    "kibana_ip = '34.0.64.248:5601'\n",
    "es_username = 'user'\n",
    "es_password = 'knesset'\n",
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.2.0)/charset_normalizer (2.0.9) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_11772\\714966622.py:24: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  resp = es.search(index=\"all_features_sentences\", body=query, scroll=\"2m\", size=1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results retrieved: 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'succeeded': True, 'num_freed': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(f'http://{elastic_ip}', basic_auth=(es_username, es_password), request_timeout=500)\n",
    "data_q =[]\n",
    "# Query definition\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"match\": {\"speaker_name\": \"מירי רגב\"}}\n",
    "            ],\n",
    "            \"filter\": {\n",
    "                \"script\": {\n",
    "                    \"script\": {\n",
    "                        \"source\": \"doc['sentence_text.keyword'].size() > 0 && doc['sentence_text.keyword'].value.length() > 10\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize scroll\n",
    "resp = es.search(index=\"all_features_sentences\", body=query, scroll=\"2m\", size=1000)\n",
    "\n",
    "# Retrieve the scroll ID and first batch of hits\n",
    "scroll_id = resp['_scroll_id']\n",
    "hits = resp['hits']['hits']\n",
    "\n",
    "total_hits = 0\n",
    "while total_hits<2000:\n",
    "    for hit in hits:\n",
    "      data_q.append(\"%(sentence_text)s\" % hit[\"_source\"])\n",
    "      #print(\"%(sentence_text)s\" % hit[\"_source\"])\n",
    "\n",
    "    total_hits += len(hits)\n",
    "\n",
    "    # Fetch the next batch\n",
    "    resp = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "    scroll_id = resp['_scroll_id']\n",
    "    hits = resp['hits']['hits']\n",
    "\n",
    "print(f\"Total results retrieved: {total_hits}\")\n",
    "\n",
    "# Clear the scroll to free resources\n",
    "es.clear_scroll(scroll_id=scroll_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for i in range(len(data_q)):\n",
    "    data_q[i] = re.sub(r'[^א-ת ]', '', data_q[i]).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim: 384 (384,)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_fn = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Encode the documents\n",
    "docs = data_q.copy()\n",
    "vectors = embedding_fn.encode(docs)  # Encode into vectors\n",
    "print(\"Dim:\", len(vectors[0]), vectors[0].shape)  # Dim: 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 2000 entities, each with fields: dict_keys(['id', 'vector', 'text'])\n",
      "Vector dim: 384\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\"id\": i, \"vector\": vectors[i], \"text\": docs[i]}\n",
    "    for i in range(len(vectors))\n",
    "]\n",
    "print(\"Data has\", len(data), \"entities, each with fields:\", data[0].keys())\n",
    "print(\"Vector dim:\", len(data[0][\"vector\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import FieldSchema, CollectionSchema, DataType, Collection\n",
    "\n",
    "# Define the collection schema\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True),\n",
    "    FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=len(vectors[0])),\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=512),\n",
    "]\n",
    "schema = CollectionSchema(fields, description=\"Demo collection for quotes of Miri Regev\")\n",
    "\n",
    "# Create or load the collection\n",
    "collection_name = \"Miri_Regev_quotes\"\n",
    "collection = Collection(name=collection_name, schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 2000 entities into Miri_Regev_quotes.\n"
     ]
    }
   ],
   "source": [
    "# Milvus expects the data in columns (field-wise)\n",
    "field_data = [\n",
    "    [entity[\"id\"] for entity in data],  # IDs\n",
    "    [entity[\"vector\"] for entity in data],  # Vectors\n",
    "    [entity[\"text\"] for entity in data],  # Text\n",
    "]\n",
    "\n",
    "# Insert the data\n",
    "res = collection.insert(field_data)\n",
    "print(f\"Inserted {len(field_data[0])} entities into {collection_name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created.\n"
     ]
    }
   ],
   "source": [
    "index_params = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 128},\n",
    "}\n",
    "collection.create_index(field_name=\"vector\", index_params=index_params)\n",
    "print(\"Index created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collections in Milvus: ['Miri_Regev_quotes']\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import list_collections\n",
    "\n",
    "collections = list_collections()\n",
    "print(\"Collections in Milvus:\", collections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = Collection(name=\"Miri_Regev_quotes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: לתחבורה הציבורית\n",
      "Text: והתחבורה הציבורית ב\n",
      "Text: קח תחבורה\n",
      "Text: עכשיו התפקיד שלנו זה להוסיף את התדירות של האוטובוסים רכבות בעזרת השם  הרכבת מקריית שמונה ועד אילת מתקדמת  רכבות קלות להביא עוד ועוד כלים של תחבורה ציבורית כדי באמת לשכנע את האזרח לוותר על הרכב ולנסוע בתחבורה הציבורית\n",
      "Text: ממשלה שאומרת שאכפת לה מהפריפריה ומהחלשים ובפועל מעלה ב את מחירי הנסיעה בתחבורה הציבורית\n",
      "Text: יש כאן בעצם ראייה כוללת שמדברת על יכולת של הנגשה וזמינות לאזרח של תחבורה ציבורית  זמינה נגישה וכמובן גם ירוקה עד כמה שניתן\n",
      "Text: אנחנו רוצים שבכל מתחמי התחנות אדם יגיע מהבית שלו ברכב דוגלגלי יחנה בתחנה ייסע ליעדו על רכבת או על אוטובוס חשמלי או אוטובוס אחר ויחזור\n",
      "Text: משרד התחבורה הוא משרד גדול משרד שיש לו אחריות אזרחית על אוויר ים ויבשה על כל הכניסה והיציאה אל הארץ ומהארץ החוצה\n",
      "Text: נדבר על הרכבת הקלה וגם על הכבדה\n",
      "Text: אני רוצה לתת עוד בשורה שהיא חשובה מאוד ולהודות כאן גם לחברי מקלב סגן השרה שהבאנו איגום משאבים ועצרנו את עליית המחירים של  בתחבורה הציבורית  עלייה שהיא באמת גזרה קשה על הציבור וזו עוד ירושה מהממשלה הקודמת\n",
      "Text: בזה שהוא מנע כסף מזומן לתחבורה הציבורית לפריפריה\n",
      "Text: בסוף האחריות האזרחית על התעופה היא של שרת התחבורה\n",
      "Text: בפריפריה מקבלים  הנחה בתחבורה ציבורית חיילים משוחררים בני ובנות שירות  ייסעו בחינם שנה בתחבורה הציבורית צעירים בכל הארץ ישלמו  פחות בתחבורה הציבורית נכים ובעלי מוגבלויות יקבלו  הנחה בתחבורה הציבורית\n",
      "Text: אני נותן טיפים לשרת התחבורה\n",
      "Text: זו החלטה של משרד התחבורה ולא של משרד הביטחון\n"
     ]
    }
   ],
   "source": [
    "collection.load()\n",
    "\n",
    "# Define a query vector (e.g., embedding for a new query)\n",
    "query_vector = embedding_fn.encode([\"מה דעתה תחבורה ציבורית?\"])[0]\n",
    "\n",
    "# Perform the search\n",
    "search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}}\n",
    "results = collection.search(\n",
    "    data=[query_vector],  # Query vector\n",
    "    anns_field=\"vector\",\n",
    "    param=search_params,\n",
    "    limit=15,  # Number of top matches\n",
    "    output_fields=[\"text\"],  # Include the text field in results\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    for hit in result:\n",
    "        print(f\"Text: {hit.entity.get('text')}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
