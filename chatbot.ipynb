{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-communityNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (3.11.11)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.13 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.3.13)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.3.28)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (0.2.6)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (1.24.2)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (2.26.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community) (8.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (0.3.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (2.10.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain-community) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain-community) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.1.1)\n",
      "Downloading langchain_community-0.3.13-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/2.5 MB 1.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.5 MB 1.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.4/2.5 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.0/2.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.3/49.3 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.13 marshmallow-3.23.2 mypy-extensions-1.0.0 pydantic-settings-2.7.1 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -elenium (c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -elenium (c:\\users\\1\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Milvus\n",
    "from langchain.llms import Ollama\n",
    "from pymilvus import connections, utility, Collection, CollectionSchema, FieldSchema, DataType\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import random\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_fn = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Connect to Milvus\n",
    "def connect_to_milvus(host=\"localhost\", port=\"19530\"):\n",
    "    connections.connect(\"default\", host=host, port=port)\n",
    "    print(\"Connected to Milvus.\")\n",
    "\n",
    "# Ensure the collection exists in Milvus\n",
    "def get_or_create_collection(collection_name, fields=None, description=\"\"):\n",
    "    if not utility.has_collection(collection_name):\n",
    "        if not fields:\n",
    "            raise ValueError(f\"Collection '{collection_name}' does not exist and no schema provided to create it.\")\n",
    "        schema = CollectionSchema(fields=fields, description=description)\n",
    "        collection = Collection(name=collection_name, schema=schema)\n",
    "        print(f\"Created collection: {collection_name}\")\n",
    "    else:\n",
    "        collection = Collection(name=collection_name)\n",
    "    return collection\n",
    "\n",
    "# Retrieve relevant context from Milvus based on the user query\n",
    "def retrieve_context(collection_name, query, top_k=15):\n",
    "    collection = get_or_create_collection(collection_name)\n",
    "    query_embedding = embedding_fn.encode(query).tolist()\n",
    "    \n",
    "    # Search for the top_k most relevant quotes\n",
    "    results = collection.search(\n",
    "        data=[query_embedding],\n",
    "        anns_field=\"vector\",  # Correct field name for embeddings\n",
    "        param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}},  # Use L2 for Euclidean distance\n",
    "        limit=top_k,\n",
    "        output_fields=[\"text\"]  # Correct field name for the quote text\n",
    "    )\n",
    "    \n",
    "    context = []\n",
    "    for result in results[0]:\n",
    "        context.append(result.entity.text)  # Use dot notation to access the text field\n",
    "    return context\n",
    "\n",
    "\n",
    "\n",
    "# Insert a new conversation history into Milvus\n",
    "def insert_to_milvus(collection_name, question, answer, embedding):\n",
    "    # Define the primary key field\n",
    "    primary_key = \"id\"\n",
    "\n",
    "    # Create or get the collection schema with a primary key\n",
    "    if not utility.has_collection(collection_name):\n",
    "        fields = [\n",
    "            FieldSchema(name=primary_key, dtype=DataType.INT64, is_primary=True),\n",
    "            FieldSchema(name=\"question\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "            FieldSchema(name=\"answer\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "            FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384),\n",
    "        ]\n",
    "        schema = CollectionSchema(fields, description=\"Chatbot conversation history\")\n",
    "        collection = Collection(name=collection_name, schema=schema)\n",
    "        print(f\"Collection '{collection_name}' created.\")\n",
    "    else:\n",
    "        collection = get_or_create_collection(collection_name)\n",
    "\n",
    "    # Generate a unique ID (e.g., using a random integer or time-based approach)\n",
    "    conversation_id = random.randint(1000000, 9999999)  # Example random ID, can be replaced with a more unique approach\n",
    "\n",
    "    # Insert the conversation data\n",
    "    entities = [\n",
    "        [conversation_id],  # Provide a valid unique ID\n",
    "        [question],\n",
    "        [answer],\n",
    "        [embedding],\n",
    "    ]\n",
    "    \n",
    "    collection.insert(entities)\n",
    "    print(\"Conversation added to Milvus.\")\n",
    "\n",
    "# Chatbot logic with RAG\n",
    "def chatbot():\n",
    "    # Connect to Milvus\n",
    "    connect_to_milvus()\n",
    "    collection_name = \"Miri_Regev_quotes\"  # Collection storing the quotes\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = Ollama(model=\"llama3.2\")  # Replace with your specific Ollama model\n",
    "\n",
    "    print(\"Chatbot with RAG is ready! Type 'exit' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        \n",
    "        # Retrieve context (quotes) from Milvus\n",
    "        context_quotes = retrieve_context(collection_name, user_input, top_k=3)\n",
    "        context_text = \"\\n\".join(context_quotes)\n",
    "\n",
    "        # Format the prompt with context and user query\n",
    "        prompt = (\n",
    "            f\"The following are quotes by Miri Regev:\\n{context_text}\\n\\n\"\n",
    "            f\"Based on the above quotes, answer the following question like you were Miri Regev, with her tone and common words\\phrases she said! answer only to the question, do not show your thinking process. ANSWER IN HEBREW!:\\n{user_input}\"\n",
    "        )\n",
    "        \n",
    "        # Generate response using the LLM\n",
    "        response = llm(prompt)\n",
    "        \n",
    "        # Store the conversation in Milvus\n",
    "        question_embedding = embedding_fn.encode(user_input).tolist()\n",
    "        insert_to_milvus(\"chatbot_history\", user_input, response, question_embedding)\n",
    "        \n",
    "        # Display the response\n",
    "        print(f\"Bot: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auto_id': False, 'description': 'Demo collection for quotes of Miri Regev', 'fields': [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': False}, {'name': 'vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 384}}, {'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 512}}], 'enable_dynamic_field': False}\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import Collection\n",
    "\n",
    "collection = Collection(\"Miri_Regev_quotes\")\n",
    "print(collection.schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chatbot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mchatbot\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chatbot' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
